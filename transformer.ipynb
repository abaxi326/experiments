{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d3634a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import keras\n",
    "import numpy as np\n",
    "\n",
    "# Hyperparameters\n",
    "num_heads = 4\n",
    "key_dim = 64\n",
    "ff_dim = 256\n",
    "input_vocab_size = 1000\n",
    "target_vocab_size = 1000\n",
    "max_len = 50\n",
    "embed_dim = num_heads * key_dim  # Must match num_heads * key_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a9e22fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(layers.Layer):\n",
    "    def __init__(self,num_heads,key_dim,ff_dim):\n",
    "        super().__init__()\n",
    "        self.attn=layers.MultiHeadAttention(num_heads,key_dim)\n",
    "        self.ffn=keras.Sequential([\n",
    "            layers.Dense(ff_dim,activation='relu'),\n",
    "            layers.Dense(embed_dim)\n",
    "        ])\n",
    "        self.norm1=layers.LayerNormalization()\n",
    "        self.norm2=layers.LayerNormalization()\n",
    "        self.dropout1 = layers.Dropout(0.1)\n",
    "        self.dropout2 = layers.Dropout(0.1)\n",
    "    \n",
    "    def call(self,inputs):\n",
    "        attn_out=self.attn(inputs,inputs)\n",
    "        x1=self.norm1(attn_out+inputs)\n",
    "        x2=self.ffn(x1)\n",
    "        out=self.norm2(x1+x2)\n",
    "        return out\n",
    "encoder=Encoder(num_heads,key_dim,ff_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "55b2a63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.random.random(size=(20,80,256))\n",
    "y=np.random.randint(0,1000,size=(20,80))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "87eaf3b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 20, 256), dtype=float32, numpy=\n",
       "array([[[-1.2127826 , -0.77087265,  0.77632517, ...,  0.8525477 ,\n",
       "         -0.348576  ,  0.869121  ],\n",
       "        [-0.2408125 , -0.34218946, -0.40675944, ...,  1.0770398 ,\n",
       "          0.17444578,  0.3869732 ],\n",
       "        [ 1.0243182 ,  0.03374228, -1.9451551 , ...,  0.3192826 ,\n",
       "          1.5060017 ,  1.551663  ],\n",
       "        ...,\n",
       "        [-1.433679  , -0.05109433, -0.92366725, ..., -0.4154136 ,\n",
       "          0.4992351 , -0.11111915],\n",
       "        [ 0.08867569, -2.5041466 ,  0.80557925, ..., -0.32401872,\n",
       "          0.9066082 ,  0.9615029 ],\n",
       "        [ 2.3308926 , -0.59212214,  0.8988739 , ..., -1.6763623 ,\n",
       "          0.36125395, -0.8192442 ]]], dtype=float32)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input=np.random.random(size=(1,20,64*4))\n",
    "encoder(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "58bd653f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(layers.Layer):\n",
    "    def __init__(self,num_heads,key_dim,ff_dim):\n",
    "        super().__init__()\n",
    "        self.attn1=layers.MultiHeadAttention(num_heads,key_dim)\n",
    "        self.attn2=layers.MultiHeadAttention(num_heads,key_dim)\n",
    "        self.norm1=layers.LayerNormalization()\n",
    "        self.norm2=layers.LayerNormalization()\n",
    "        self.norm3=layers.LayerNormalization()\n",
    "        self.ffn=keras.Sequential([\n",
    "            layers.Dense(ff_dim,activation='relu'),\n",
    "            layers.Dense(embed_dim)\n",
    "        ])\n",
    "        self.final=layers.Dense(1000)\n",
    "\n",
    "    def call(self,inputs,encoder_out):\n",
    "        attn1=self.attn1(inputs,inputs)\n",
    "        norm1=self.norm1(attn1+inputs)\n",
    "        attn2=self.attn2(inputs,encoder_out,encoder_out)\n",
    "        norm2=self.norm2(attn2+norm1)\n",
    "        ffn=self.ffn(norm2)\n",
    "        norm3=self.norm3(ffn+norm2)\n",
    "        out=self.final(norm3)\n",
    "        return out\n",
    "decoder=Decoder(num_heads,key_dim,ff_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e5944483",
   "metadata": {},
   "outputs": [],
   "source": [
    "output=np.random.random(size=(1,20,64*4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5e36ba62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 20, 256)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1d4aff48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 20, 1000), dtype=float32, numpy=\n",
       "array([[[-0.05834087, -0.18001312, -0.06784771, ..., -0.8585679 ,\n",
       "         -0.35062277, -0.90648115],\n",
       "        [ 0.48854625, -0.63146025,  1.4996128 , ...,  0.10885578,\n",
       "         -0.7751333 ,  0.25545335],\n",
       "        [ 0.25171676, -0.6617282 ,  0.06840431, ..., -0.9687251 ,\n",
       "          0.40246302,  0.16524458],\n",
       "        ...,\n",
       "        [ 0.16209333,  0.54144454,  0.6200061 , ..., -0.27395976,\n",
       "          0.4443381 ,  1.187688  ],\n",
       "        [ 0.2857694 ,  1.5800495 , -0.3480262 , ..., -0.49839073,\n",
       "         -0.6645607 ,  0.02672759],\n",
       "        [-0.5273811 , -0.94447374,  0.215056  , ...,  0.15271834,\n",
       "         -0.5571054 , -0.97469854]]], dtype=float32)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder(input,input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8bea9571",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "class Transformer(keras.Model):\n",
    "    def __init__(self,encoder,decoder):\n",
    "        super().__init__()\n",
    "        self.encoder=encoder\n",
    "        self.decoder=decoder\n",
    "        \n",
    "    def call(self,inputs):\n",
    "        en_out=self.encoder(inputs)\n",
    "        dec_out=self.decoder(inputs,en_out)\n",
    "        return dec_out\n",
    "    \n",
    "    def train_step(self,data):\n",
    "        print('in train_step')\n",
    "        x,y=data\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred=self(x)\n",
    "            loss=self.compiled_loss(y,y_pred)\n",
    "        train_vars=self.trainable_variables\n",
    "        grads=tape.gradient(loss,train_vars)\n",
    "        self.optimizer.apply_gradients(zip(grads,train_vars))\n",
    "        self.compiled_metrics.update_state(y, y_pred)\n",
    "\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "31bd6bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Transformer(encoder,decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3b2c4f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.SparseCategoricalCrossentropy(),optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "41782704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in train_step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\a3318\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:671: UserWarning: `model.compiled_loss()` is deprecated. Instead, use `model.compute_loss(x, y, y_pred, sample_weight, training)`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\a3318\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:646: UserWarning: `model.compiled_metrics()` is deprecated. Instead, use e.g.:\n",
      "```\n",
      "for metric in self.metrics:\n",
      "    metric.update_state(y, y_pred)\n",
      "```\n",
      "\n",
      "  return self._compiled_metrics_update_state(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in train_step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - loss: -0.0100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x23d4fbfaf90>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x,y,epochs=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
